<h1 align="center">Student Dropout and Academic Success Prediction</h1>
Submitted by:
Shashanka Oruganti.

introduction = """
# Project Title: Student Dropout and Academic Success Prediction

## Introduction
This project involves a dataset created from a higher education institution. 
The primary goal is to predict students' dropout and academic success. 
By identifying key factors that influence these outcomes, we aim to help educational institutions improve their support systems, 
academic advising, and retention strategies.

## Dataset Origin and Collection
The dataset originates from a higher education institution and includes data collected at the time of student enrollment. 
This data encompasses various aspects such as:
- Academic path
- Demographics
- Socio-economic factors and many more.

The data was collected through institutional records, student surveys, and other administrative data sources.

## Fields in the Dataset
The dataset includes the following fields:
- **Student ID**: Unique identifier for each student
- **Enrollment Year**: The year the student enrolled
- **Course**: The course or major the student is enrolled in
- **Age**: Age of the student at the time of enrollment
- **Gender**: Gender of the student
- **High School GPA**: GPA from high school
- **Entrance Exam Score**: Scores from standardized entrance exams
- **Family Income**: Socio-economic status of the studentâ€™s family
- **Scholarship**: Whether the student received a scholarship (Yes/No)
- **Part-Time Job**: Whether the student has a part-time job (Yes/No)
- **Residence**: Whether the student lives on-campus or off-campus
- **Parent Education Level**: The highest education level attained by the student's parents
- **Dropout Status**: Whether the student dropped out, is currently enrolled, or graduated

## **Data Preparation:**
### **1. Import necessary libraries like pandas, LabelEncoder, StandardScaler**
```
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
```
### **2. Load the Dataset**
```
file_path = 'data.csv'
data = pd.read_csv(file_path)
```
### **3. Display the structure of the dataset**
```
print("Dataset Info:")
print(data.info())
```

dataset_info = """
## Dataset Information

```python
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 4424 entries, 0 to 4423
Data columns (total 37 columns):
 #   Column                                          Non-Null Count  Dtype  
---  ------                                          --------------  -----  
 0   Marital status                                  4424 non-null   int64  
 1   Application mode                                4424 non-null   int64  
 2   Application order                               4424 non-null   int64  
 3   Course                                          4424 non-null   int64  
 4   Daytime/evening attendance                      4424 non-null   int64  
 5   Previous qualification                          4424 non-null   int64  
 6   Previous qualification (grade)                  4424 non-null   float64
 7   Nacionality                                     4424 non-null   int64  
 8   Mother's qualification                          4424 non-null   int64  
 9   Father's qualification                          4424 non-null   int64  
 10  Mother's occupation                             4424 non-null   int64  
 11  Father's occupation                             4424 non-null   int64  
 12  Admission grade                                 4424 non-null   float64
 13  Displaced                                       4424 non-null   int64  
 14  Educational special needs                       4424 non-null   int64  
 15  Debtor                                          4424 non-null   int64  
 16  Tuition fees up to date                         4424 non-null   int64  
 17  Gender                                          4424 non-null   int64  
 18  Scholarship holder                              4424 non-null   int64  
 19  Age at enrollment                               4424 non-null   int64  
 20  International                                   4424 non-null   int64  
 21  Curricular units 1st sem (credited)             4424 non-null   int64  
 22  Curricular units 1st sem (enrolled)             4424 non-null   int64  
 23  Curricular units 1st sem (evaluations)          4424 non-null   int64  
 24  Curricular units 1st sem (approved)             4424 non-null   int64  
 25  Curricular units 1st sem (grade)                4424 non-null   float64
 26  Curricular units 1st sem (without evaluations)  4424 non-null   int64  
 27  Curricular units 2nd sem (credited)             4424 non-null   int64  
 28  Curricular units 2nd sem (enrolled)             4424 non-null   int64  
 29  Curricular units 2nd sem (evaluations)          4424 non-null   int64  
 30  Curricular units 2nd sem (approved)             4424 non-null   int64  
 31  Curricular units 2nd sem (grade)                4424 non-null   float64
 32  Curricular units 2nd sem (without evaluations)  4424 non-null   int64  
 33  Unemployment rate                               4424 non-null   float64
 34  Inflation rate                                  4424 non-null   float64
 35  GDP                                             4424 non-null   float64
 36  Target                                          4424 non-null   object 
dtypes: float64(7), int64(29), object(1)
memory usage: 1.2+ MB
None
```

### **4. Check for Missing Values**
```
missing_values = data.isnull().sum()
print("\nMissing Values:")
print(missing_values[missing_values > 0])
```

```
Missing Values:
Series([], dtype: int64)
```

### **5. Data Types and Encoding**

```
label_encoder = LabelEncoder()
data['Target'] = label_encoder.fit_transform(data['Target'])
label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))
print("\nLabel Mapping for Target Column:")
print(label_mapping)
```

```
Label Mapping for Target Column:
{'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}
```

### **6. Normalization/Scaling
```
numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns
scaler = StandardScaler()
data[numerical_cols] = scaler.fit_transform(data[numerical_cols])
print("\nFirst Few Rows of Scaled Data:")
print(data.head())
```

```

First Few Rows of Scaled Data:
   Marital status  Application mode  Application order    Course  \
0       -0.294829         -0.095470           2.490896 -4.209520   
1       -0.294829         -0.209869          -0.554068  0.192580   
2       -0.294829         -1.010660           2.490896  0.103404   
3       -0.294829         -0.095470           0.207173  0.444115   
4        1.356212          1.162916          -0.554068 -0.408389   

   Daytime/evening attendance\t  Previous qualification  \
0                      0.350082                -0.35023   
1                      0.350082                -0.35023   
2                      0.350082                -0.35023   
3                      0.350082                -0.35023   
4                     -2.856470                -0.35023   

   Previous qualification (grade)  Nacionality  Mother's qualification  \
0                       -0.804841    -0.126298               -0.036018   
1                        2.076819    -0.126298               -1.189759   
2                       -0.804841    -0.126298                1.117723   
3                       -0.804841    -0.126298                1.181819   
4                       -2.473171    -0.126298                1.117723   

   Father's qualification  ...  Curricular units 2nd sem (credited)  \
0               -0.669778  ...                            -0.282442   
1               -1.256427  ...                            -0.282442   
2                0.959802  ...                            -0.282442   
3                0.959802  ...                            -0.282442   
4                1.024985  ...                            -0.282442   

   Curricular units 2nd sem (enrolled)  \
0                            -2.838337   
1                            -0.105726   
2                            -0.105726   
3                            -0.105726   
4                            -0.105726   

   Curricular units 2nd sem (evaluations)  \
0                               -2.042630   
1                               -0.522682   
2                               -2.042630   
3                                0.490616   
4                               -0.522682   

   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \
0                            -1.471527                         -1.963489   
1                             0.518904                          0.659562   
2                            -1.471527                         -1.963489   
3                             0.187165                          0.416450   
4                             0.518904                          0.531608   

   Curricular units 2nd sem (without evaluations)  Unemployment rate  \
0                                       -0.199441          -0.287638   
1                                       -0.199441           0.876222   
2                                       -0.199441          -0.287638   
3                                       -0.199441          -0.813253   
4                                       -0.199441           0.876222   

   Inflation rate       GDP  Target  
0        0.124386  0.765761       0  
1       -1.105222  0.347199       2  
2        0.124386  0.765761       0  
3       -1.466871 -1.375511       2  
4       -1.105222  0.347199       2  

[5 rows x 37 columns]
```

### **7. Plotting the Distribution of the Target Classes**

```
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))
sns.countplot(x='Target', data=data, palette='viridis')
plt.title('Class Distribution of Target Variable')
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.xticks(ticks=[0, 1, 2], labels=['Dropout', 'Enrolled', 'Graduate'])
plt.show()
```
![alt text]("C:\Users\oruga\Downloads\figure_1.png")

### **8. Plot the distributions of selected features**

```
features_to_plot = [
    'Admission grade', 
    'Age at enrollment', 
    'Curricular units 1st sem (grade)', 
    'Curricular units 2nd sem (grade)'
]

plt.figure(figsize=(14, 10))

for i, feature in enumerate(features_to_plot, 1):
    plt.subplot(2, 2, i)
    sns.histplot(data[feature], kde=True, bins=30, palette='viridis')
    plt.title(f'Distribution of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()
```

![alt text]("C:\Users\oruga\Downloads\figure_2.png")

### **8. Plot the correlation matrix with increased figure size and better readability**

```
plt.figure(figsize=(16, 14))
correlation_matrix = data.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={"size": 10}, cbar_kws={"shrink": 0.8})
plt.title('Correlation Matrix', size=15)
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.yticks(fontsize=10)
plt.show()
```
![alt text]("C:\Users\oruga\Downloads\figure_3.png")

### **9. Splitting the Dataset into Training and Testing Sets**

```
from sklearn.model_selection import train_test_split
X = data.drop(columns=['Target'])
y = data['Target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
```

```
((3539, 36), (885, 36), (3539,), (885,))
```

### **10. Training and Evaluating the Logistic Regression Model**

```
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
logreg = LogisticRegression(class_weight='balanced', random_state=42)
logreg.fit(X_train, y_train)
y_pred_logreg = logreg.predict(X_test)
logreg_report = classification_report(y_test, y_pred_logreg, target_names=['Dropout', 'Enrolled', 'Graduate'])
print("Logistic Regression Report:")
print(logreg_report)
```

```
Logistic Regression Report:
              precision    recall  f1-score   support

     Dropout       0.85      0.68      0.76       284
    Enrolled       0.41      0.64      0.50       159
    Graduate       0.86      0.79      0.82       442

    accuracy                           0.73       885
   macro avg       0.70      0.70      0.69       885
weighted avg       0.77      0.73      0.74       885
```

### **11. Training and Evaluating the Descision tree classifier**

```
from sklearn.tree import DecisionTreeClassifier
decision_tree = DecisionTreeClassifier(class_weight='balanced', random_state=42)
decision_tree.fit(X_train, y_train)
y_pred_tree = decision_tree.predict(X_test)
tree_report = classification_report(y_test, y_pred_tree, target_names=['Dropout', 'Enrolled', 'Graduate'])
print("Decision Tree Report:")
print(tree_report)
```

```
Decision Tree Report:
              precision    recall  f1-score   support

     Dropout       0.68      0.64      0.66       284
    Enrolled       0.36      0.43      0.39       159
    Graduate       0.78      0.75      0.76       442

    accuracy                           0.66       885
   macro avg       0.60      0.61      0.60       885
weighted avg       0.67      0.66      0.66       885
```

### **12. Training and Evaluating the Gradient Boosting Model**

```
from sklearn.ensemble import GradientBoostingClassifier
gradient_boosting = GradientBoostingClassifier(random_state=42)
gradient_boosting.fit(X_train, y_train)
y_pred_gb = gradient_boosting.predict(X_test)
gb_report = classification_report(y_test, y_pred_gb, target_names=['Dropout', 'Enrolled', 'Graduate'])
print("Gradient Boosting Report:")
print(gb_report)
```

```
Gradient Boosting Report:
              precision    recall  f1-score   support

     Dropout       0.80      0.73      0.76       284
    Enrolled       0.53      0.41      0.46       159
    Graduate       0.80      0.90      0.85       442

    accuracy                           0.76       885
   macro avg       0.71      0.68      0.69       885
weighted avg       0.75      0.76      0.75       885
```

### **13. Hyperparameter Tuning with GridSearchCV for Random Forest**

```
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

rf = RandomForestClassifier(class_weight='balanced', random_state=42)
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, 
                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')

grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
best_score = grid_search.best_score_

best_params, best_score
```
```
({'bootstrap': True,
  'max_depth': None,
  'min_samples_leaf': 1,
  'min_samples_split': 2,
  'n_estimators': 100},
 0.7739490039917003)
 ```

 ### **14. Training and Evaluating the Best Random Forest Model**

 ```
best_rf = RandomForestClassifier(
    n_estimators=best_params['n_estimators'],
    max_depth=best_params['max_depth'],
    min_samples_split=best_params['min_samples_split'],
    min_samples_leaf=best_params['min_samples_leaf'],
    bootstrap=best_params['bootstrap'],
    class_weight='balanced',
    random_state=42
)

best_rf.fit(X_train, y_train)
y_pred_best_rf = best_rf.predict(X_test)
best_rf_report = classification_report(y_test, y_pred_best_rf, target_names=['Dropout', 'Enrolled', 'Graduate'])
print("Best Random Forest Report:")
print(best_rf_report)
```

```
Best Random Forest Report:
              precision    recall  f1-score   support

     Dropout       0.82      0.75      0.78       284
    Enrolled       0.59      0.38      0.46       159
    Graduate       0.79      0.94      0.86       442

    accuracy                           0.78       885
   macro avg       0.73      0.69      0.70       885
weighted avg       0.77      0.78      0.76       885
```

### **15. Visualizing Feature Importances from the Best Random Forest Model**

```
import matplotlib.pyplot as plt
import seaborn as sns
feature_importances = best_rf.feature_importances_
feature_names = X.columns
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=importance_df)
plt.title('Feature Importances in Random Forest')
plt.show()
```

![alt text]("C:\Users\oruga\Downloads\figure_4.png")

### **16. Evaluating the Model with Cross-Validation**

```
from sklearn.model_selection import cross_val_score
cv_scores = cross_val_score(best_rf, X_train, y_train, cv=5, scoring='accuracy')
print(f'Cross-validation scores: {cv_scores}')
print(f'Mean cross-validation score: {cv_scores.mean()}')
```

```
Cross-validation scores: [0.77683616 0.78954802 0.78107345 0.79378531 0.76944837]
Mean cross-validation score: 0.7821382622523754
```

### **17. Computing and Plotting the Confusion Matrix**

```
from sklearn.metrics import confusion_matrix
import seaborn as sns
conf_matrix = confusion_matrix(y_test, y_pred_best_rf)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Dropout', 'Enrolled', 'Graduate'], yticklabels=['Dropout', 'Enrolled', 'Graduate'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()
```
![alt text]("C:\Users\oruga\Downloads\figure_5.png")

### **18. Computing and Plotting the Precision-Recall Curves**

```
from sklearn.metrics import precision_recall_curve
from sklearn.preprocessing import label_binarize
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])
n_classes = y_test_bin.shape[1]
plt.figure(figsize=(12, 8))
for i in range(n_classes):
    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_pred_best_rf == i)
    plt.plot(recall, precision, marker='.', label=f'Class {i}')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend()
plt.show()
```

![alt text]("C:\Users\oruga\Downloads\figure_6.png")

### **19. Computing and Plotting the ROC Curves and AUC**

```
from sklearn.metrics import roc_curve, auc
plt.figure(figsize=(12, 8))
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_best_rf == i)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, marker='.', label=f'Class {i} (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()
```

![alt text]("C:\Users\oruga\Downloads\figure_7.png")

### **20. Comprehensive Hyperparameter Tuning with GridSearchCV for Random Forest**

```
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
param_grid = {
    'n_estimators': [100, 200, 300, 400, 500],
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 5, 10, 15],
    'min_samples_leaf': [1, 2, 4, 6],
    'bootstrap': [True, False]
}

rf = RandomForestClassifier(class_weight='balanced', random_state=42)
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, 
                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')

grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
best_score = grid_search.best_score_

best_params, best_score
```

### **21. Hyperparameter Tuning with RandomizedSearchCV for Random Forest**

```
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import randint
param_dist = {
    'n_estimators': randint(100, 500),
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': randint(2, 15),
    'min_samples_leaf': randint(1, 6),
    'bootstrap': [True, False]
}

rf = RandomForestClassifier(class_weight='balanced', random_state=42)
random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, 
                                   n_iter=100, cv=3, n_jobs=-1, verbose=2, random_state=42, scoring='accuracy')

random_search.fit(X_train, y_train)
best_params = random_search.best_params_
best_score = random_search.best_score_

best_params, best_score
```

```
({'bootstrap': False,
  'max_depth': 30,
  'min_samples_leaf': 1,
  'min_samples_split': 2,
  'n_estimators': 227},
 0.7716876793988968)
 ```

 ### **22. Training and Evaluating a Voting Classifier**

 ```
 from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
logreg = LogisticRegression(class_weight='balanced', random_state=42)
tree = DecisionTreeClassifier(class_weight='balanced', random_state=42)
rf = RandomForestClassifier(class_weight='balanced', random_state=42)
gb = GradientBoostingClassifier(random_state=42)
voting_clf = VotingClassifier(estimators=[
    ('logreg', logreg),
    ('tree', tree),
    ('rf', rf),
    ('gb', gb)
], voting='hard')

voting_clf.fit(X_train, y_train)
y_pred_voting = voting_clf.predict(X_test)
voting_report = classification_report(y_test, y_pred_voting, target_names=['Dropout', 'Enrolled', 'Graduate'])
print("Voting Classifier Report:")
print(voting_report)
```

```
Voting Classifier Report:
              precision    recall  f1-score   support

     Dropout       0.81      0.75      0.78       284
    Enrolled       0.51      0.50      0.51       159
    Graduate       0.82      0.87      0.85       442

    accuracy                           0.76       885
   macro avg       0.72      0.71      0.71       885
weighted avg       0.76      0.76      0.76       885
```

### **23. Feature Selection and Model Training with Selected Features**

```
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import RandomForestClassifier

best_rf_params = {
    'bootstrap': False,
    'max_depth': 30,
    'min_samples_leaf': 1,
    'min_samples_split': 2,
    'n_estimators': 227,
    'class_weight': 'balanced',
    'random_state': 42
}

rf = RandomForestClassifier(**best_rf_params)
rf.fit(X_train, y_train)
selector = SelectFromModel(rf, threshold='mean', prefit=True)
X_train_selected = selector.transform(X_train)
X_test_selected = selector.transform(X_test)
rf_selected = RandomForestClassifier(**best_rf_params)
rf_selected.fit(X_train_selected, y_train)
y_pred_selected = rf_selected.predict(X_test_selected)
selected_report = classification_report(y_test, y_pred_selected, target_names=['Dropout', 'Enrolled', 'Graduate'])
print("Random Forest with Selected Features Report:")
print(selected_report)
```

```
Random Forest with Selected Features Report:
              precision    recall  f1-score   support

     Dropout       0.81      0.72      0.76       284
    Enrolled       0.53      0.38      0.44       159
    Graduate       0.78      0.91      0.84       442

    accuracy                           0.76       885
   macro avg       0.71      0.67      0.68       885
weighted avg       0.75      0.76      0.75       885
```

### **24. Extensive Hyperparameter Tuning with RandomizedSearchCV for Random Forest**

```
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import randint

param_dist = {
    'n_estimators': randint(100, 500),
    'max_depth': [None, 20, 30, 40, 50],
    'min_samples_split': randint(2, 15),
    'min_samples_leaf': randint(1, 5),
    'bootstrap': [True, False]
}

rf = RandomForestClassifier(class_weight='balanced', random_state=42)
random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, 
                                   n_iter=100, cv=3, n_jobs=-1, verbose=2, random_state=42, scoring='accuracy')
random_search.fit(X_train, y_train)
best_params = random_search.best_params_
best_score = random_search.best_score_
print("Best Parameters:", best_params)
print("Best Score:", best_score)
```

```
Fitting 3 folds for each of 100 candidates, totalling 300 fits
Best Parameters: {'bootstrap': False, 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 212}
Best Score: 0.7705586942875078
```

### **25. Creating and Evaluating Polynomial Features**

```
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=2, include_bias=False)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)
model_poly = RandomForestClassifier(random_state=42)
model_poly.fit(X_train_poly, y_train)
y_pred_poly = model_poly.predict(X_test_poly)
print(classification_report(y_test, y_pred_poly))
```

```
              precision    recall  f1-score   support

           0       0.80      0.75      0.77       284
           1       0.58      0.40      0.48       159
           2       0.80      0.92      0.85       442

    accuracy                           0.77       885
   macro avg       0.73      0.69      0.70       885
weighted avg       0.76      0.77      0.76       885
```

### **26. Evaluating the Final Model with Classification Report and Confusion Matrix**

```
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import shap
import matplotlib.pyplot as plt
import seaborn as sns

final_model = RandomForestClassifier(
    bootstrap=False,
    max_depth=30,
    min_samples_leaf=1,
    min_samples_split=2,
    n_estimators=300
)

final_model.fit(X_train, y_train)
y_pred = final_model.predict(X_test)

print("Classification Report:")
print(classification_report(y_test, y_pred))

print("Confusion Matrix:")
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Dropout', 'Enrolled', 'Graduate'], yticklabels=['Dropout', 'Enrolled', 'Graduate'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix - Final Model')
plt.show()
```

```
Classification Report:
              precision    recall  f1-score   support

     Dropout       0.85      0.76      0.80       316
    Enrolled       0.55      0.35      0.43       151
    Graduate       0.78      0.94      0.85       418

    accuracy                           0.78       885
   macro avg       0.72      0.68      0.69       885
weighted avg       0.76      0.78      0.76       885
```
![alt text]("C:\Users\oruga\Downloads\figure_8.png")

## **27. Evaluating Feature Importance Using Permutation Importance**
```
from sklearn.inspection import permutation_importance
import matplotlib.pyplot as plt
import numpy as np

# Fit the final model again if needed
final_model = RandomForestClassifier(
    bootstrap=False,
    max_depth=30,
    min_samples_leaf=1,
    min_samples_split=2,
    n_estimators=300
)
final_model.fit(X_train, y_train)

# Compute permutation feature importance
perm_importance = permutation_importance(final_model, X_test, y_test, n_repeats=30, random_state=42, n_jobs=-1)

# Get importance and sort them
importance = perm_importance.importances_mean
indices = np.argsort(importance)

# Plot
plt.figure(figsize=(12, 8))
plt.title('Feature Importance - Permutation')
plt.barh(range(len(indices)), importance[indices], align='center')
plt.yticks(range(len(indices)), [X_test.columns[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()
```
![alt text]("C:\Users\oruga\Downloads\figure_9.png")

### **28. Generating and Integrating Polynomial Features into the Dataset**

```
from sklearn.preprocessing import PolynomialFeatures
features = ['Curricular units 1st sem (evaluations)', 'Curricular units 2nd sem (evaluations)', 'Admission grade']
poly = PolynomialFeatures(degree=2, interaction_only=True)
poly_features = poly.fit_transform(df[features])
poly_df = pd.DataFrame(poly_features, columns=poly.get_feature_names_out(features))
df_poly = pd.concat([df, poly_df], axis=1)
df_poly.head()
```

```
Marital status	Application mode	Application order	Daytime/evening attendance\t	Previous qualification	Previous qualification (grade)	Nacionality	Mother's qualification	Father's qualification	Mother's occupation	...	Age_bins	Total_credits_1st_sem	Avg_grade	1	Curricular units 1st sem (evaluations)	Curricular units 2nd sem (evaluations)	Admission grade	Curricular units 1st sem (evaluations) Curricular units 2nd sem (evaluations)	Curricular units 1st sem (evaluations) Admission grade	Curricular units 2nd sem (evaluations) Admission grade
0	1	17	5	1	1	122.0	1	19	12	5	...	1	0	0.000000	1.0	0.0	0.0	127.3	0.0	0.0	0.0
1	1	15	1	1	1	160.0	1	1	3	3	...	1	6	13.833333	1.0	6.0	6.0	142.5	36.0	855.0	855.0
2	1	1	5	1	1	122.0	1	37	37	9	...	1	6	0.000000	1.0	0.0	0.0	124.8	0.0	0.0	0.0
3	1	17	2	1	1	122.0	1	38	37	5	...	1	6	12.914286	1.0	8.0	10.0	119.6	80.0	956.8	1196.0
4	2	39	1	0	1	100.0	1	37	38	9	...	6	6	12.666667	1.0	9.0	6.0	141.5	54.0	1273.5	849.0
5 rows Ã— 59 columns
```

### **29. Training and Evaluating the Final Model with Polynomial Features** 

```
# Drop target column for training
X = df_poly.drop(columns=['Target'])
y = df_poly['Target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)
final_model_poly = RandomForestClassifier(bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300)
final_model_poly.fit(X_train, y_train)
y_pred_poly = final_model_poly.predict(X_test)
print("Classification Report:")
print(classification_report(y_test, y_pred_poly))

print("Confusion Matrix:")
conf_matrix_poly = confusion_matrix(y_test, y_pred_poly)
sns.heatmap(conf_matrix_poly, annot=True, fmt='d', cmap='Blues', xticklabels=['Dropout', 'Enrolled', 'Graduate'], yticklabels=['Dropout', 'Enrolled', 'Graduate'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix - Final Model with Polynomial Features')
plt.show()
```

```
Classification Report:
              precision    recall  f1-score   support

     Dropout       0.85      0.77      0.81       316
    Enrolled       0.54      0.34      0.42       151
    Graduate       0.77      0.93      0.84       418

    accuracy                           0.77       885
   macro avg       0.72      0.68      0.69       885
weighted avg       0.76      0.77      0.76       885

```

![alt text]("C:\Users\oruga\Downloads\figure_10.png")

### **30.  Ranking and Visualizing Feature Importances of the Final Model with Polynomial Features**
```
import numpy as np

importances = final_model_poly.feature_importances_
indices = np.argsort(importances)[::-1]
print("Feature ranking:")

for f in range(X_train.shape[1]):
    print(f"{f + 1}. feature {X_train.columns[indices[f]]} ({importances[indices[f]]})")

plt.figure(figsize=(12, 8))
plt.title("Feature importances")
plt.bar(range(X_train.shape[1]), importances[indices], align="center")
plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)
plt.xlim([-1, X_train.shape[1]])
plt.show()
```

```
Feature ranking:
1. feature Curricular units 2nd sem (approved) (0.1356417773893516)
2. feature Avg_grade (0.09409118925008772)
3. feature Curricular units 1st sem (approved) (0.08595276821289653)
4. feature Tuition fees up to date (0.043950412336791596)
5. feature Curricular units 2nd sem (evaluations) Admission grade (0.03800149951128418)
6. feature Curricular units 1st sem (evaluations) Admission grade (0.03371137872644552)
7. feature Curricular units 1st sem (evaluations) Curricular units 2nd sem (evaluations) (0.03299828871022915)
8. feature Admission grade (0.031337753308513946)
9. feature Admission grade (0.031163287756853092)
10. feature Previous qualification (grade) (0.029762541442187724)
11. feature Age at enrollment (0.028257175611136064)
12. feature Father's occupation (0.023802128379439094)
13. feature Curricular units 2nd sem (evaluations) (0.0235249558357033)
14. feature Curricular units 2nd sem (evaluations) (0.023174025276882004)
15. feature Mother's occupation (0.021589796607328536)
16. feature Curricular units 1st sem (evaluations) (0.021379316105284155)
17. feature Curricular units 1st sem (evaluations) (0.019949768123774077)
18. feature GDP (0.01953487209754729)
19. feature Curricular units 2nd sem (enrolled) (0.01907515157506474)
20. feature Unemployment rate (0.018334127388921356)
21. feature Total_credits_1st_sem (0.017660355960751342)
22. feature Father's qualification (0.01753524107829249)
23. feature Inflation rate (0.017221196572345623)
24. feature Mother's qualification (0.016952450842537624)
25. feature Application mode (0.01686275817549685)
26. feature Scholarship holder (0.014824800609066055)
27. feature Age_bins (0.014480422908241163)
28. feature Application order (0.012053501092246833)
29. feature Debtor (0.009569482962719032)
30. feature Gender (0.008384689086791774)
31. feature Displaced (0.006410298525268992)
32. feature Course_9853 (0.0058032327723971855)
33. feature Curricular units 2nd sem (credited) (0.0048575309739807004)
34. feature Previous qualification (0.004843230750898018)
35. feature Course_9119 (0.004458005800341312)
36. feature Course_171 (0.004407461171605231)
37. feature Course_9500 (0.004016446385475942)
38. feature Course_9238 (0.003971150125412068)
39. feature Curricular units 1st sem (without evaluations) (0.003955129415800014)
40. feature Curricular units 2nd sem (without evaluations) (0.0035493528642354445)
41. feature Course_9085 (0.003186649245372824)
42. feature Marital status (0.0027380329595003902)
43. feature Course_9670 (0.0027122185912750816)
44. feature Course_9147 (0.0026698781500831435)
45. feature Course_9773 (0.002588418183131021)
46. feature Course_9254 (0.0022203983154767603)
47. feature Course_9991 (0.0021987815013263575)
48. feature Course_9070 (0.002197719928055076)
49. feature Daytime/evening attendance	 (0.0021765144442680686)
50. feature Nacionality (0.002071848950900821)
51. feature Course_9130 (0.0020604827168418903)
52. feature Course_8014 (0.001603890936824635)
53. feature International (0.0013605101063323564)
54. feature Course_9003 (0.0012218412869793942)
55. feature Course_9556 (0.0010180927415153864)
56. feature Educational special needs (0.0008719222741712016)
57. feature Course_33 (5.3847948320191235e-05)
58. feature 1 (0.0)
```

![alt text]("C:\Users\oruga\Downloads\figure_11.png")


## Utility of the Dataset
This dataset is useful for:
- Identifying patterns and factors that influence student success and dropout rates
- Helping educational institutions to design better support systems and interventions
- Improving academic advising and resource allocation
- Enhancing retention strategies to reduce dropout rates

## Prediction Objective
The objective of this project is to predict the academic outcome of students at the end of their course duration. 
The possible outcomes are:
- Dropout
- Enrolled
- Graduate

## Practical Applications
In production or practice, this prediction can be used to:
- **Early Intervention**: Identify students at risk of dropping out early and provide them with necessary support.
- **Resource Allocation**: Allocate resources more efficiently by targeting students who need the most help.
- **Policy Making**: Inform policy decisions regarding student support programs and educational strategies.
- **Personalized Education**: Offer personalized academic advising and support based on predicted outcomes.
"""

process_overview = """
## Process Overview

### Narrative of Experience
During the project, several iterative approaches were taken. 
Initially, data cleaning and preprocessing were conducted to handle missing values and outliers.
 Exploratory Data Analysis (EDA) was performed to understand the data distribution and relationships between features.

## Exploratory Data Analysis (EDA)

### X and Y Variables
- **X Variables**: All fields except for Dropout Status.
- **Y Variable**: Dropout Status.

### Classification Task
This project is a three-category classification task, predicting whether a student will drop out, remain enrolled, or graduate.

### Number of Observations
The dataset includes a substantial number of observations. Details on the exact number of observations will be provided in the EDA section.

### Feature to Observation Ratio
A discussion on the ratio of features to observations will be provided, ensuring that the dataset is well-suited for machine learning tasks.

### Distribution of Features
The distribution of each feature will be analyzed. 
Special focus will be given to features that are imbalanced or may present problems during model training.

### Target Variable Distribution
The distribution of the target variable, Dropout Status, 
will be examined to understand the proportion of each class (dropout, enrolled, graduate).

### Correlation Analysis
A correlation analysis will be performed to identify strongly correlated features. 
This analysis helps in understanding relationships between variables and in feature selection.

### Feature Importance
Feature importance will be assessed to determine which features are most influential in predicting student outcomes.
 A case for using all features or selecting specific features will be made based on this analysis.

## Feature Engineering

### Label Encoding vs. One-Hot Encoding
A discussion on the encoding techniques used for categorical variables, including label encoding and one-hot encoding.

### Cross Features and Advanced Engineering
Any advanced feature engineering techniques applied, such as creating cross features or other transformations, 
will be discussed in this section.
"""

model_fitting = """
## Model Fitting

### Train/Test Splitting
The dataset was split into training and testing sets to evaluate the model's performance.
 The train/test split ratio was carefully chosen to ensure a representative sample for both training and validation.

### Data Leakage Prevention
Special attention was given to prevent data leakage, which could lead to overly optimistic performance estimates.
 This is particularly important for time-series datasets, although not applicable here.

### Model Selection
Several models were considered, including:
- Linear Regression
- Logistic Regression
- Support Vector Classifier (SVC/SVM)
- Decision Trees (including Random Forests)

The selection of the final model was based on performance metrics and the specific requirements of the classification task.

### Hyperparameter Tuning
Hyperparameters were optimized using methods such as GridSearch and cross-validation to find the best-performing model configuration. 
The process for hyperparameter selection is outlined in detail.

## Validation and Metrics

### Key Metrics
The following metrics were used to evaluate model performance:
- Accuracy
- Balanced Accuracy
- ROC-AUC
- Precision
- Recall

### Confusion Matrix
A confusion matrix was created to provide a detailed view of the model's performance across different classes. 
This helps in understanding the model's strengths and weaknesses.

### Model Weaknesses
An analysis of the model's weaknesses is provided, highlighting areas where the model may underperform or produce biased predictions.

### Prediction Examples
Examples of predictions from the dataset are given to illustrate the model's application. Additionally, 
two synthesized prediction examples are provided to demonstrate how the model generalizes to new data.

### Overfitting/Underfitting
The potential for overfitting or underfitting was evaluated. Techniques to mitigate these issues, 
such as regularization or more data collection, were applied as necessary.
"""

production_future = """
## Production

### Deployment Advice
For deploying this model, consider the following:
- **Scalability**: Ensure that the infrastructure can handle the volume of data and the required prediction speed.
- **Monitoring**: Implement monitoring to track the model's performance over time and detect any drift in data or model performance.
- **Maintenance**: Regularly retrain the model with new data to keep it up-to-date and accurate.
- **Ethical Considerations**: Be mindful of the ethical implications of using the model, especially in terms of fairness and bias.

### Precautions
- **Data Privacy**: Ensure that student data is handled in compliance with data protection regulations.
- **Model Bias**: Regularly check for and mitigate any biases in the model to ensure fair treatment of all students.
- **Interpretability**: Maintain model interpretability to ensure that the predictions can be understood and acted upon by educators and administrators.

## Going Further

### Potential Improvements
Several areas could be explored to enhance the model:
- **More Data**: Collecting additional data, especially from different institutions, can improve model generalization.
- **Additional Features**: Incorporating new features such as attendance records, participation in extracurricular activities, and student feedback could provide a more comprehensive view.
- **Data Augmentation**: Techniques such as data augmentation could be used to create more diverse training examples.
- **Advanced Models**: Experimenting with advanced models like neural networks or ensemble methods could potentially improve performance.
- **Feature Selection**: Continuously evaluating and selecting the most relevant features to improve model accuracy and efficiency.
- **Regular Updates**: Regularly updating the model with the latest data to maintain its accuracy and relevance.

By implementing these improvements, the model's predictive power and applicability in real-world educational settings can be significantly enhanced.
"""

# Combining all sections
readme_content = introduction + process_overview + model_fitting + production_future

with open("README.md", "w") as file:
    file.write(readme_content)


